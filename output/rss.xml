<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>sahiga</title><link>http://www.stephaniehiga.com</link><description>The personal website of Stephanie A. Higa.</description><lastBuildDate>Sun, 19 May 2013 00:09:34 GMT</lastBuildDate><generator>nikola</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Analyzing Rap Lyrics with Python</title><link>http://www.stephaniehiga.com/posts/analyzing-rap-lyrics-with-python.html</link><description>&lt;p&gt;Yesterday my company held a hack day for the developers to work on independent projects. I used the opportunity to jumpstart a text mining project I've had on my mind for months: an analysis of rap lyrics. More specifically, I ran a quick-and-dirty experiment to find the most beloved car brand in hip-hop.&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://stephaniehiga.com/cars.html#results"&gt;Skip to the results here.&lt;/a&gt;&lt;/p&gt;
&lt;div class="section" id="why-hip-hop"&gt;
&lt;h2&gt;Why hip-hop?&lt;/h2&gt;
&lt;p&gt;Hip-hop is by far my favorite genre of music. I don't listen to much else. On the road, I tune the radio to 93.5 KDAY; otherwise, I'm plugged into my Pandora account, which is heavy on Golden Age, Midwestern, East Coast, Bay Area, and (recently) indie rap. Someday I'll give podcasts/NPR/classical music a whirl. But that someday is a long while away.&lt;/p&gt;
&lt;p&gt;Hip-hop also seems to be lyrically denser than other types of music. It's wordy, which means it contains quite a bit of text to analyze.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="why-car-brands"&gt;
&lt;h2&gt;Why car brands?&lt;/h2&gt;
&lt;p&gt;Rappers talk about cars. A lot. Now, maybe it's because I like Chevy trucks, but I've heard plenty of songs that mention "Chevy" (okay, and Benz and Cadillac too). So I decided to find out once and for all which car brand rappers loved the most. Chevy was, of course, my pick.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="my-method"&gt;
&lt;h2&gt;My method&lt;/h2&gt;
&lt;p&gt;To find the answer, I needed a sizeable sample of car brand names, a searchable database of hip-hop lyrics, a script to search for the brands within the lyrics database, and a way of displaying the results. Fortunately, all the necessary tools were readily available:&lt;/p&gt;
&lt;ul class="simple"&gt;&lt;li&gt;Python&lt;/li&gt;
&lt;li&gt;Wikipedia&lt;/li&gt;
&lt;li&gt;LibreOffice Calc&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://research.blackyouthproject.com/raplyrics/"&gt;Rap Lyrics Database&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://developers.google.com/chart/"&gt;Google Charts&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Bootstrap&lt;/li&gt;
&lt;/ul&gt;&lt;div class="section" id="gathering-the-data"&gt;
&lt;h3&gt;Gathering the data&lt;/h3&gt;
&lt;p&gt;Wikipedia blocks web scrapers, understandably. So I manually downloaded all of Wikipedia's lists of car manufacturers and brands by country. To reduce the amount of HTML I would have to parse, I selected the &lt;a class="reference external" href="http://en.m.wikipedia.org/wiki/Main_Page"&gt;Mobile View&lt;/a&gt; for each page.&lt;/p&gt;
&lt;p&gt;I downloaded ten files in total: a general list of car manufacturers plus individual lists for China, France, Germany, Italy, Japan, Spain, Sweden, the United Kingdom, and the United States.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="cleaning-the-data"&gt;
&lt;h3&gt;Cleaning the data&lt;/h3&gt;
&lt;p&gt;Wikipedia's Mobile View pages contain search bars at the top and the usual "See also," "References," and "Read in another language" links. I started by erasing these (manually again), reducing the files to structural markup and the lists themselves.&lt;/p&gt;
&lt;p&gt;With the Python &lt;a class="reference external" href="http://www.crummy.com/software/BeautifulSoup/"&gt;Beautiful Soup&lt;/a&gt; library, I extracted the brand name tags by selecting all list elements. Then I used &lt;a class="reference external" href="http://www.nltk.org"&gt;NLTK&lt;/a&gt; to remove the HTML tags and regular expressions to remove excess whitespace and text (such as notes about the brand, the brand's years of operation, etc.). This is what I came up with:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
def clean_wikilist(filename):
    # open saved html file
    html = open(filename).read()

    # collect bulleted items only
    bullets = SoupStrainer("li")

    # make soup out of the bulleted items
    soup = BeautifulSoup(html, 'lxml', parse_only = bullets).prettify()

    # remove html from soup
    raw = nltk.clean_html(soup)

    # remove extra lines
    raw = re.sub(r'\n \n \n \n \n', r'\n', raw)
    raw = re.sub(r'\n \n \n', r'\n', raw)

    # create and clean tokens
    tokens = raw.split('\n')
    tokens = [re.sub(r'^\s+(?=[\S]+)', r'', token) for token in tokens]
    tokens = [token for token in tokens if not re.findall(r'\[[0-9]+\]|\([\S\s]+[\(\)]?|^\s+$|^[\s\[\]\(\)0-9]+$', token)]
    tokens = list(set(tokens))

    return tokens
&lt;/pre&gt;
&lt;p&gt;After running my script on all ten lists, I had a whopping &lt;strong&gt;2599 results&lt;/strong&gt;. So I decided to limit the set to Germany, Japan, the UK, and the US. The pages for Germany, the UK, and the US separate current brands from defunct brands, so for those countries I used current brands only. The Japan page mixes current and defunct brands into one list, and I didn't have time to distinguish them, so I ended up using all of them.&lt;/p&gt;
&lt;p&gt;These four pages had slightly different structures. The &lt;tt class="docutils literal"&gt;clean_wikilist()&lt;/tt&gt; script worked nicely for Japan, but captured too much information on the others, so I wrote three additional scripts. Here's the one for Germany:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
def autos_ge():
        # open saved html file
        html = open('autos-ge.html').read()

        # create soup object
        soup = BeautifulSoup(html)

        # select current major manufacturers
        majors = soup.select('span.mw-headline')
        majors = [w for w in majors if w.parent.parent.previous_sibling.contents[0]['id'] == 'Current_major_manufacturers']
        major_tokens = [nltk.clean_html(str(w)) for w in majors]
        major_tokens = [re.sub(r'\[\s\S\s\]', r'', token) for token in major_tokens]

        # select current minor manufacturers
        minors = soup.select('li')
        minors = [w for w in minors if w.parent.parent.previous_sibling.contents[0]['id'] == 'Current_minor_manufacturers']
        minor_tokens = [nltk.clean_html(str(w)) for w in minors]
        minor_tokens = [re.sub(r'\s\(\S+\)', r'', token) for token in minor_tokens]

        # combine lists
        tokens = list(set(minor_tokens + major_tokens))

        return tokens
&lt;/pre&gt;
&lt;p&gt;One notable difference between this and the original script is the usage of Beautiful Soup. In &lt;tt class="docutils literal"&gt;clean_wikilist()&lt;/tt&gt;, the desired elements are selected first, with SoupStrainer, and then used to create a list of the matching HTML tags in unicode format. &lt;tt class="docutils literal"&gt;autos_ge()&lt;/tt&gt;, on the other hand, creates a Beautiful Soup object out of the entire page; the desired elements are selected via DOM traversal.&lt;/p&gt;
&lt;p&gt;The number of the results from this limited dataset? Just 178.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="analyzing-the-data"&gt;
&lt;h3&gt;Analyzing the data&lt;/h3&gt;
&lt;p&gt;The Rap Lyrics Database contains lyrics for all of Billboard Music's rap songs from 1989 through 2009. It's the only searchable database of hip-hop lyrics (exclusively).&lt;/p&gt;
&lt;p&gt;The result pages share the same URL, with the search term appended to the end: &lt;em&gt;http://research.blackyouthproject.com/raplyrics/results/?all/1989-2009/&lt;/em&gt;. This made it much easier to automate the search and saving process:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
def rap_search(auto_list):
    # search for each brand name
    for brand in auto_list:
        url = 'http://research.blackyouthproject.com/raplyrics/results/?all/1989-2009/' + word

        # save the search results page
        results_html = urllib2.urlopen(url).read()

        # save it as a file named after the brand
        results = word + '.html'

        with open(results, 'w') as results_file:
            results_file.write(results_html)
&lt;/pre&gt;
&lt;p&gt;This saved 178 HTML pages, each named after the appropriate brand search term, onto my computer. I also searched for known nicknames of the brands (e.g. "Bimmer/Beemer/Beamer" for BMW and "Chevy" for Chevrolet, etc.).&lt;/p&gt;
&lt;p&gt;I used Beautiful Soup again to count the number of results on each page:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
def count_rap_results():
        # for all html files in current directory
        for filename in os.listdir('.'):
        if filename.endswith('html'):

        # select song titles
        html = open(filename).read()
        soup = BeautifulSoup(html)
        songs = soup.select('.title')

        # count number of song titles
        count = len(songs)

        # write brand names and number of songs into a text file
        with open('count_rap_autos.txt', 'a') as counter_file:
                counter_file.write('%s%15d\n' % (filename[:-5], count))
&lt;/pre&gt;
&lt;p&gt;This got me a pretty messy-looking text file of each brand and the number of songs in which it was mentioned:&lt;/p&gt;
&lt;blockquote&gt;
Lea-Francis              1
Ewing              0
Efini              0
Scion              0
Tommy Kaira             15
...&lt;/blockquote&gt;
&lt;p&gt;It turned out that the Rap Lyrics Database doesn't recognize spaces. So, a search for "Art and Tech" became a search for "Art"--which of course is a popular word that is often used in a non-automobile context. I removed ambiguous names from the list and combined the results from brands and their nicknames. LibreOffice Calc was helpful in fixing the columns and sorting the results.&lt;/p&gt;
&lt;p&gt;The final number of usable brands came out to 153.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="who-won"&gt;
&lt;h2&gt;Who won?&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Mercedes-Benz&lt;/strong&gt;, with &lt;strong&gt;93 song mentions&lt;/strong&gt;--and remember, that's only counting a small segment of rap songs between 1989-2009.&lt;/p&gt;
&lt;p&gt;Jeep came in second, at 34 songs. Then came Cadillac with 25 songs, and finally Chevy at 24.&lt;/p&gt;
&lt;p&gt;So, Chevy isn't as popular as I expected. But the biggest surprise here is Jeep. I can't recall a single song that mentions Jeep.&lt;/p&gt;
&lt;p&gt;I made a &lt;a class="reference external" href="http://stephaniehiga.com/cars.html#results"&gt;graph and table&lt;/a&gt; to display the results. (I'd add them here, but I've yet to learn how to embed JavaScript into reStructuredText.)&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="pain-points"&gt;
&lt;h2&gt;Pain points&lt;/h2&gt;
&lt;p&gt;I'm new to programming. While I enjoy it very much, I spend about 90% of my time immersed in pain. The text analysis took me four nights (Monday through Thursday) to complete. On the actual hack day, I made the graph and web page, with a lot of Bootstrap help. Along the way, I encountered many problems:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;p class="first"&gt;Selecting specific subsets of HTML tags with no classes or ids.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Accidentally passing list items with the newline character to the &lt;tt class="docutils literal"&gt;rap_search()&lt;/tt&gt; script, resulting in 178 filenames split off from their extensions. Fortunately there was an easy fix:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
for filename in os.listdir("."):
        if '\n' in filename:
        os.rename(filename, re.sub(r'\n', r'', filename))
&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Reformatting the final list of brands into an HTML table.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Reformatting the final list of brands into a list of dictionaries to create a graph with &lt;a class="reference external" href="http://philogb.github.io/jit/"&gt;JavaScript InfoVis Toolkit&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Not knowing how to build a non-stacked bar graph with the InfoVis Toolkit.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Switching to Google Charts and reformatting the final list of brands into a list of lists to create a Google Charts graph.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;/div&gt;
&lt;div class="section" id="notes-for-the-future"&gt;
&lt;h2&gt;Notes for the future&lt;/h2&gt;
&lt;div class="section" id="more-complete-data"&gt;
&lt;h3&gt;More complete data&lt;/h3&gt;
&lt;p&gt;I slashed the set of brand names to less than 7% of its original size and conflated "car manufacturers" with "car brands." Wikipedia also has a lengthy &lt;a class="reference external" href="https://en.wikipedia.org/wiki/List_of_automobile_marques"&gt;list of automobile marques&lt;/a&gt;, which I didn't even touch.&lt;/p&gt;
&lt;p&gt;I'd like to go deeper than brands, into the actual names of cars, and match them against an even bigger database of lyrics. &lt;a class="reference external" href="http://www.rapgenius.com"&gt;RapGenius&lt;/a&gt; and the &lt;a class="reference external" href="http://www.last.fm/api"&gt;Last.fm API&lt;/a&gt; are possible alternatives to the Rap Lyrics Database. RapGenius has an excellent database, but it contains a significant amount of lyrics from non-hip-hop artists as well.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="semantic-orientation"&gt;
&lt;h3&gt;Semantic orientation&lt;/h3&gt;
&lt;p&gt;I equated "beloved" to "number of songs mentions." This is obviously not always the case, as rappers name-drop plenty of things they dislike. It's true that rappers generally mention cars in a positive manner, but a more accurate experiment would take into account not just how many times the brand was used, but in what way the brand was used--i.e., the semantic orientation of the brand.&lt;/p&gt;
&lt;p&gt;I might have to attempt a &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Sentiment_analysis"&gt;sentiment analysis&lt;/a&gt; for this.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="multi-word-brands"&gt;
&lt;h3&gt;Multi-word brands&lt;/h3&gt;
&lt;p&gt;The Rap Lyrics Database turns up blank if you search for, say "Aston Martin" (with the quotes and the space), even though Aston Martin is mentioned in a few songs. So multi-word brands with spaces in them turned up short. (Mercedes-Benz doesn't have this issue because it has a hyphen, not a space.)&lt;/p&gt;
&lt;p&gt;If I were to use the Rap Lyrics Database again, I'd have to search for "Aston" and "Martin" separately and compare the songs on each results page. Otherwise, RapGenius seems to do spaces nicely.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="nicknames-and-duplicates"&gt;
&lt;h3&gt;Nicknames and duplicates&lt;/h3&gt;
&lt;p&gt;Mercedes-Benz is often referred to as just "Mercedes" or just "Benz." While I searched for the full name and both nicknames, I ended up using the results for the full name only to minimize the possibility of duplicates (as I found the number of results, but not the actual song titles).&lt;/p&gt;
&lt;p&gt;Again, I'll have to compare song results against each other to ensure that there are no duplicates in the count.&lt;/p&gt;
&lt;p&gt;I also missed some nicknames--for instance, I completely neglected "Caddy" and "Lac" (sorry, Cadillac), "Lex," etc.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="misspellings-plurals-etc"&gt;
&lt;h3&gt;Misspellings, plurals, etc.&lt;/h3&gt;
&lt;p&gt;I did search for "Beamer" and "Beemer," but there's also "Bima" and probably countless other misspellings of "Bimmer" and other car brands, too. I ignored plurals to save time.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="disambiguation"&gt;
&lt;h3&gt;Disambiguation&lt;/h3&gt;
&lt;p&gt;Many car brands double as common words or unrelated proper names: Prince, Radical, Ram, MINI, Oakland, etc. I discarded these instead of determining whether or not they were referring to the car brand.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="last-thoughts"&gt;
&lt;h3&gt;Last thoughts&lt;/h3&gt;
&lt;p&gt;A few months ago, when I first got the idea for this project, I thought it would be ridiculously hard. I'd have to build a large corpus of hip-hop lyrics and determine the classification and orientation of each word to uncover the truth.&lt;/p&gt;
&lt;p&gt;After going about this somewhat backwards, I think my initial impression remains correct. I'm happy I finally took a stab at this project, and I'm really excited to continue working on it. There's so much more to analyze and discover in hip-hop!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>hip-hop + rap</category><category>python</category><category>text mining</category><guid>http://www.stephaniehiga.com/posts/analyzing-rap-lyrics-with-python.html</guid><pubDate>Sat, 18 May 2013 18:32:32 GMT</pubDate></item><item><title>Text-Based Web Browsing</title><link>http://www.stephaniehiga.com/posts/text-based-web-browsing.html</link><description>&lt;div class="section" id="w3m"&gt;
&lt;h2&gt;w3m&lt;/h2&gt;
&lt;p&gt;w3m is a text-based web browser, first released in 1995.&lt;/p&gt;
&lt;ul class="simple"&gt;&lt;li&gt;"Opening socket"&lt;/li&gt;
&lt;li&gt;Viewing[SSL]&lt;/li&gt;
&lt;li&gt;shows you the names of cookies you're receiving&lt;/li&gt;
&lt;li&gt;lowercase "v" shows HTML source of webpage&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;What I like about w3m:&lt;/p&gt;
&lt;ul class="simple"&gt;&lt;li&gt;No ads&lt;/li&gt;
&lt;li&gt;Consistent, uniform fonts and colors.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;What I don't like:&lt;/p&gt;
&lt;ul class="simple"&gt;&lt;li&gt;No omnibox: Pressing &lt;strong&gt;Shift + U&lt;/strong&gt; gets you into the address bar, but, obviously, you can't type in a search term and have it redirect to a DuckDuckGo (Google, Bing, etc.) search for that term.&lt;/li&gt;
&lt;/ul&gt;&lt;/div&gt;
&lt;div class="section" id="textonly"&gt;
&lt;h2&gt;TextOnly&lt;/h2&gt;
&lt;p&gt;Now, I could &lt;strong&gt;really&lt;/strong&gt; use something like w3m on my phone[*]. The closest I could find is &lt;a class="reference external" href="https://play.google.com/store/apps/details?id=com.spacenext.textonly"&gt;TextOnly&lt;/a&gt;, a text-based web browser for Android 1.6+.&lt;/p&gt;
&lt;p&gt;Unfortunately, w3m it's not. The interface is befuddling. It offers three different options for viewing a page: RSS Feed, Links, and Normal. I prefer the "Normal" dislay to the other two.&lt;/p&gt;
&lt;table class="docutils footnote" frame="void" id="id2" rules="none"&gt;&lt;colgroup&gt;&lt;col class="label"&gt;&lt;col&gt;&lt;/colgroup&gt;&lt;tbody valign="top"&gt;&lt;tr&gt;&lt;td class="label"&gt;[*]&lt;/td&gt;&lt;td&gt;My phone is an HTC Droid Eris, &lt;cite&gt;one of the first ten Android phones released and one of the first two Android phones released by Verizon &amp;lt;http://www.androidphonesarena.com/2009-android-phones.php&amp;gt;&lt;/cite&gt;, along with the Motorola Droid. It does wonderfully for a 3.5-year old phone, but it chokes on resource-heavy websites.&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;div class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: WARNING/2 (&lt;tt class="docutils"&gt;&amp;lt;string&amp;gt;&lt;/tt&gt;, line 45)&lt;/p&gt;
Explicit markup ends without a blank line; unexpected unindent.&lt;/div&gt;
&lt;p&gt;&lt;a class="reference external" href="http://www.dolphin-browser.com"&gt;Dolphin&lt;/a&gt; is a beautiful and intuitive browser&lt;/p&gt;
&lt;/div&gt;</description><category>w3m</category><guid>http://www.stephaniehiga.com/posts/text-based-web-browsing.html</guid><pubDate>Tue, 07 May 2013 20:18:24 GMT</pubDate></item><item><title>GitHub for Linux Mint</title><link>http://www.stephaniehiga.com/posts/github-for-linux-mint.html</link><description>&lt;p&gt;Version control terrifies me.&lt;/p&gt;
&lt;p&gt;But you know what else terrifies me? Losing files. I've lost enough of them and endured enough filename headaches (story-1.doc, story-2.doc, story-final, story-new.doc, story-newEST.doc, etc.) in my lifetime to realize that &lt;strong&gt;version control is extremely important&lt;/strong&gt;, and I need to develop better version control habits.&lt;/p&gt;
&lt;p&gt;So, I added the files for this site to &lt;a class="reference external" href="https://github.com/sahiga/sah"&gt;my GitHub account&lt;/a&gt;. The following guide details the steps I took, minus the legion of errors I made. I've named it "GitHub for &lt;a class="reference external" href="http://www.linuxmint.com"&gt;Linux Mint&lt;/a&gt;," in honor of my operating system and the fact that GitHub offers &lt;a class="reference external" href="http://mac.github.com"&gt;GitHub for Mac&lt;/a&gt; and &lt;a class="reference external" href="http://windows.github.com"&gt;GitHub for Windows&lt;/a&gt;, but no GitHub for GNU/Linux (even though, hey, some of us GNU/Linux users could use a little point-and-click help over here).&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Note: Afterward, I realized I could have had a &lt;a class="reference external" href="https://help.github.com/articles/fetching-a-remote"&gt;much easier time&lt;/a&gt; cloning the repository. This command is identical to the "Clone in Windows" and "Clone in Mac" buttons in the corresponding GitHub GUI applications:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
git clone &amp;lt;URL&amp;gt;
&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;div class="section" id="connect-your-computer-to-github"&gt;
&lt;h2&gt;Connect your computer to GitHub&lt;/h2&gt;
&lt;p&gt;First, you need a secure method of connecting your computer to GitHub. You can do this through SSH (generate a new public/private SSH key pair and add it to your GitHub account) or through HTTPS (configure the Git credential helper).&lt;/p&gt;
&lt;ul class="simple"&gt;&lt;li&gt;&lt;a class="reference external" href="https://help.github.com/articles/set-up-git"&gt;Instructions for using HTTPS with GitHub&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://help.github.com/articles/generating-ssh-keys"&gt;Instructions for using SSH with GitHub&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/div&gt;
&lt;div class="section" id="prepare-the-branches"&gt;
&lt;h2&gt;Prepare the branches&lt;/h2&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/new"&gt;Create a new repository on GitHub&lt;/a&gt;. This is the &lt;strong&gt;remote branch&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Fire up your command line. Move to the directory containing your version control files (if you're not there already), e.g., &lt;tt class="docutils literal"&gt;cd sah&lt;/tt&gt;.&lt;/p&gt;
&lt;p&gt;Initialize a Git repository in this directory. This is the &lt;strong&gt;local branch&lt;/strong&gt;.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
git init
&lt;/pre&gt;
&lt;p&gt;Check the status of your new repository.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
git status
&lt;/pre&gt;
&lt;p&gt;(or &lt;tt class="docutils literal"&gt;git st&lt;/tt&gt; if you've set up &lt;a class="reference external" href="http://git-scm.com/book/ch2-7.html#Git-Aliases"&gt;aliases&lt;/a&gt;). This is optional, but I like checking the status to see which branch I'm working on and which files will be included in the next commit.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
# On branch master
# Untracked files:
#   (use "git add &amp;lt;file&amp;gt;..." to include in what will be committed)
#
#       .doit.db
#       1.txt
#       README.txt
#       cache/
#       conf.py
#       conf.pyc
#       conf.py~
#       files/
#       galleries/
#       listings/
#       new_site/
#       output/
#       posts/
#       stephanieahiga.wordpress.2013-05-05.xml
#       stories/
nothing added to commit but untracked files present (use "git add" to track)
&lt;/pre&gt;
&lt;p&gt;Right now there's "nothing added to commit," meaning the local repository is empty. This is because you've just initialized it.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="start-tracking-your-files"&gt;
&lt;h2&gt;Start tracking your files&lt;/h2&gt;
&lt;p&gt;Next, add version control tracking to your files. To add individual files, write &lt;tt class="docutils literal"&gt;git add&lt;/tt&gt; and then the filename. To add everything in the directory to your commit:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
git add .
&lt;/pre&gt;
&lt;p&gt;Now it's time to commit the change. The basic commit command is &lt;tt class="docutils literal"&gt;git commit&lt;/tt&gt;, which will launch your preferred text editor. The &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;-m&lt;/span&gt;&lt;/tt&gt; flag allows you to skip the text editor and type your commit message inline; the &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;-a&lt;/span&gt;&lt;/tt&gt; flag tells Git to automatically stage your tracked files, skipping the staging area.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
git commit -a -m "Added Nikola site files"
&lt;/pre&gt;
&lt;p&gt;See &lt;a class="reference external" href="http://git-scm.com/book/en/Git-Basics-Recording-Changes-to-the-Repository"&gt;Git Basics - Recording Changes to the Repository&lt;/a&gt; for more information on committing changes.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="merge-and-sync-your-branches"&gt;
&lt;h2&gt;Merge and sync your branches&lt;/h2&gt;
&lt;p&gt;Merge the remote branch (the GitHub copy of the repository) with your local branch (the local copy of the repository). This consolidates the two branches and ensures that they are identical.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
git pull https://github.com/sahiga/sah.git
&lt;/pre&gt;
&lt;p&gt;You should see a message like this:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
From https://github.com/sahiga/sah
 * branch            HEAD       -&amp;gt; FETCH_HEAD
Merge made by the 'recursive' strategy.
 README.md |    4 ++++
 1 file changed, 4 insertions(+)
 create mode 100644 README.md


**Note:** ``git pull`` automatically merges commits from the "pulled" branch into your current branch. This works fine on an empty GitHub repository, but it could cause `merge conflicts &amp;lt;https://help.github.com/articles/fetching-a-remote&amp;gt;`_.
&lt;/pre&gt;
&lt;p&gt;Push your commit on the local branch to the remote branch:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
git push origin master
&lt;/pre&gt;
&lt;p&gt;If you're using HTTPS, GitHub will prompt you for credentials. To switch to SSH, &lt;a class="reference external" href="https://help.github.com/articles/why-is-git-always-asking-for-my-password"&gt;follow these instructions&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;strong&gt;Note:&lt;/strong&gt; I originally attempted &lt;tt class="docutils literal"&gt;git push origin master&lt;/tt&gt; before &lt;tt class="docutils literal"&gt;git pull&lt;/tt&gt;, resulting in a "non-fast-forward" error. This error occurs when the local branch is behind the remote branch, and therefore Git can't push the local commits without losing commits on the remote branch. GitHub has an &lt;a class="reference external" href="https://help.github.com/articles/dealing-with-non-fast-forward-errors"&gt;article on non-fast-forward errors&lt;/a&gt; that I wish I'd found when I made this mistake.&lt;/blockquote&gt;
&lt;p&gt;The two branches are now in sync! Check the commit history in your local branch with &lt;tt class="docutils literal"&gt;git log&lt;/tt&gt;. The most recent commit should have a "Merge" attribute, identical to what you'll find in the "Commits" tab in your GitHub account:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
    commit e9bcc38554dd930b4bd1f557e45c92f8f65e0a98
    Merge: 3e653b4 96d590b
    Author: sahiga
    Date:   Sat May 4 23:51:39 2013 -0700

Merge https://github.com/sahiga/sah
&lt;/pre&gt;
&lt;p&gt;Tutorials for Git and GitHub:&lt;/p&gt;
&lt;ul class="simple"&gt;&lt;li&gt;&lt;a class="reference external" href="http://git-scm.com/book"&gt;Pro Git&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://help.github.com/"&gt;GitHub Help&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www.floraworley.com/2013/03/11/get-started-with-git-and-github/"&gt;Diary of a Future Dev&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/div&gt;</description><category>linux</category><category>git</category><category>version control</category><guid>http://www.stephaniehiga.com/posts/github-for-linux-mint.html</guid><pubDate>Sun, 05 May 2013 21:05:00 GMT</pubDate></item><item><title>Goodbye, WordPress! Hello, Nikola!</title><link>http://www.stephaniehiga.com/posts/goodbye-wordpress-hello-nikola.html</link><description>&lt;p&gt;It's official: I've finally migrated my personal website from &lt;a class="reference external" href="http://www.wordpress.org"&gt;WordPress&lt;/a&gt; to &lt;a class="reference external" href="http://nikola.ralsina.com.ar"&gt;Nikola&lt;/a&gt;, a static site generator. In my 53432099809th attempt to return to writing, I'll use this bit of nerd news to jumpstart what I hope will become a regular blogging habit.&lt;/p&gt;
&lt;div class="section" id="the-quest-for-static"&gt;
&lt;h2&gt;The quest for static&lt;/h2&gt;
&lt;p&gt;WordPress gets a lot of hate in the development community. Let me say upfront that this is absolutely not the reason I decided to leave it (I have the softest of spots for WordPress). It's just that one day I woke up and realized I didn't need a database and a gazillion server queries to post text on my website.&lt;/p&gt;
&lt;p&gt;So I started looking into static site generators. A static site generator does exactly what's written on the box: it creates a static site. It combines the best of Web 1.0 (fast, portable, secure HTML pages) with the best of Web 2.0 (templates). I considered:&lt;/p&gt;
&lt;ul class="simple"&gt;&lt;li&gt;&lt;a class="reference external" href="http://jekyllrb.com/"&gt;Jekyll&lt;/a&gt; + &lt;a class="reference external" href="http://www.octopress.org"&gt;Octopress&lt;/a&gt;: Hooks directly into &lt;a class="reference external" href="http://pages.github.com/"&gt;GitHub Pages&lt;/a&gt; and is apparently very good. But I don't know Ruby, so I kept looking.&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://ringce.com/hyde"&gt;Hyde&lt;/a&gt;: A Python port of Jekyll. Ultimately, I passed on it because of the lack of documentation. When it comes to technology, this Luddite needs a lot of hand-holding.&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://docs.getpelican.com"&gt;Pelican&lt;/a&gt;: Also Python-based, with complete, well-written documentation. I installed it and got lost while trying to generate files. Pelican looks like a great choice, but I think it's meant for people who are much more tech-savvy than I am.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Shortly after I installed Pelican, someone posted a link to &lt;a class="reference external" href="http://nikola.ralsina.com.ar"&gt;Nikola&lt;/a&gt; on Hacker News. I'm not sure why it didn't come up in all my searches for Python-based static site generators, because so far it's proven to be a dream come true. The documentation is amazing. It's easy to use and in active development. And it was named after &lt;a class="reference external" href="http://theoatmeal.com/comics/tesla"&gt;Nikola Tesla&lt;/a&gt;. (&lt;strong&gt;Huge&lt;/strong&gt; Nikola Tesla fan here.)&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="goodbye-wordpress"&gt;
&lt;h2&gt;Goodbye, WordPress&lt;/h2&gt;
&lt;p&gt;Nikola has an &lt;tt class="docutils literal"&gt;import_wordpress&lt;/tt&gt; function to ease the transition to WordPress. I grabbed an XML dump of my site (&lt;strong&gt;Tools &amp;gt; Export &amp;gt; All Content&lt;/strong&gt; in the WP admin panel) and saved it in my Nikola site folder.&lt;/p&gt;
&lt;p&gt;I installed the Python &lt;a class="reference external" href="https://pypi.python.org/pypi/requests"&gt;requests&lt;/a&gt; package (import_wordpress depends on requests):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
sudo pip install requests
&lt;/pre&gt;
&lt;p&gt;Then I ran import_wordpress on the file:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
nikola import_wordpress stephanieahiga.wordpress.2013-05-05.xml
&lt;/pre&gt;
&lt;p&gt;This created a new folder, &lt;strong&gt;new_site&lt;/strong&gt;, within the Nikola folder. I had no posts and only a handful of pages in my WordPress database, so I recreated the pages manually using the page command: &lt;tt class="docutils literal"&gt;nikola new_post &lt;span class="pre"&gt;-p&lt;/span&gt;&lt;/tt&gt;. Similar to WordPress, Nikola differentiates between posts and pages: posts are in the &lt;strong&gt;posts&lt;/strong&gt; folder and pages are in the &lt;strong&gt;stories&lt;/strong&gt; folder.&lt;/p&gt;
&lt;p&gt;Finally, I uninstalled WordPress from my domain via &lt;a class="reference external" href="https://www.simplescripts.com"&gt;SimpleScripts&lt;/a&gt; on my cPanel.&lt;/p&gt;
&lt;p&gt;import_wordpress saves all posts and pages with the &lt;tt class="docutils literal"&gt;.wp&lt;/tt&gt; extension (read by my computer as WordPerfect files). The XML dump, and therefore the folder created by import_wordpress, save the contents of the WordPress database, but &lt;strong&gt;not&lt;/strong&gt; the theme files. So it's important to backup any custom themes before uninstalling WordPress.&lt;/p&gt;
&lt;p&gt;Tutorials on importing WordPress posts into Nikola:&lt;/p&gt;
&lt;ul class="simple"&gt;&lt;li&gt;&lt;a class="reference external" href="http://nikola.ralsina.com.ar/handbook.html#importing-your-wordpress-site-into-nikola"&gt;Official site&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://flexion.org/posts/2012-10-migrating-wordpress-to-nikola.html"&gt;Flexion.Org&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://kushaldas.in/posts/importing-your-wordpress-blog-to-nikola.html"&gt;Kushal Das&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/div&gt;
&lt;div class="section" id="hello-nikola"&gt;
&lt;h2&gt;Hello, Nikola&lt;/h2&gt;
&lt;p&gt;I assume that the next step is to upload the Nikola site folder to my domain server. If you're reading this post, you can assume that my assumption turned out to be true.&lt;/p&gt;
&lt;/div&gt;</description><category>static site generators</category><category>nikola</category><category>wordpress</category><guid>http://www.stephaniehiga.com/posts/goodbye-wordpress-hello-nikola.html</guid><pubDate>Sat, 04 May 2013 14:09:26 GMT</pubDate></item></channel></rss>